# app/main.py
from __future__ import annotations

import os
import sys
import tempfile
import time
from pathlib import Path

import pandas as pd
import streamlit as st
import yaml

# (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) —Å–¥–µ–ª–∞–µ–º —à–∏—Ä–æ–∫—É—é —Ä–∞—Å–∫–ª–∞–¥–∫—É
st.set_page_config(page_title="CSV Normalizer ‚Äî MVP", layout="wide")

# PYTHONPATH ‚Üí –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from core.pipeline.runner import run_pipeline  # noqa: E402

APP_TITLE = "CSV Normalizer ‚Äî MVP"
SETTINGS_PATH = ROOT / "configs" / "app_settings.yaml"


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ settings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
DEFAULT_SETTINGS = {
    "save_dir": str((ROOT / "out").resolve()),
    "out_name": "normalized.csv",
    "log_name": "normalize_log.txt",
    "profile": "configs/profiles/uni.yaml",
    "delimiter": ",",
    "encoding": "auto",
    "chunksize": 100_000,

    "dedup_enabled": False,
    "dedup_field": "",
    "dedup_merge_columns": [],

    "estimate_total_rows": True,

    # —Ñ–∏–ª—å—Ç—Ä —Å—Ç—Ä–æ–∫: —É–¥–∞–ª—è—Ç—å, –µ—Å–ª–∏ —Ä–æ–≤–Ω–æ 1 –Ω–µ–ø—É—Å—Ç–∞—è —Å—Ä–µ–¥–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    "row_filter_one_filled_enabled": False,
    "row_filter_subset": [],

    # –æ—á–∏—Å—Ç–∫–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    "min_length_enabled": False,
    "min_length_value": 3,
    "min_length_columns": [],
    # —Ç–µ–ª–µ—Ñ–æ–Ω—ã: –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π –∫–æ–¥ —Å—Ç—Ä–∞–Ω—ã (E.164)
    # –≤—ã–∫–ª—é—á–µ–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    "phone_prefix_strict_validate": False,
}


def load_settings() -> dict:
    try:
        if SETTINGS_PATH.exists():
            with open(SETTINGS_PATH, "r", encoding="utf-8") as f:
                data = yaml.safe_load(f) or {}
            return {**DEFAULT_SETTINGS, **data}
    except Exception:
        pass
    return dict(DEFAULT_SETTINGS)


def save_settings(data: dict) -> None:
    try:
        SETTINGS_PATH.parent.mkdir(parents=True, exist_ok=True)
        with open(SETTINGS_PATH, "w", encoding="utf-8") as f:
            yaml.safe_dump(data, f, allow_unicode=True, sort_keys=True)
    except Exception:
        pass


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def read_columns_head(path: str, delimiter: str, encoding: str) -> list[str]:
    """–ü—Ä–æ—á–∏—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ CSV, –≤–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫."""
    if not path or not Path(path).exists():
        return []
    try_order = [encoding] if encoding != "auto" else ["utf-8", "cp1251", "latin1"]
    for enc in try_order:
        try:
            df = pd.read_csv(path, sep=delimiter, nrows=0, dtype=str, keep_default_na=False, encoding=enc)
            return list(df.columns)
        except Exception:
            continue
    return []


def folder_picker(label: str, start_path: str | Path | None = None, key: str = "folder_picker") -> str:
    """–ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≤–æ–¥–Ω–∏–∫ –ø–∞–ø–æ–∫ –≤ —Å–∞–π–¥–±–∞—Ä–µ. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—É—é –ø–∞–ø–∫—É."""
    st.sidebar.subheader(label)

    if f"{key}__cwd" not in st.session_state:
        base = Path(start_path) if start_path else Path.cwd()
        st.session_state[f"{key}__cwd"] = str(base.resolve())

    cwd = Path(st.session_state[f"{key}__cwd"])
    manual_path = st.sidebar.text_input("–¢–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞", value=str(cwd), key=f"{key}__manual_path")

    cols = st.sidebar.columns([1, 1, 2])
    with cols[0]:
        if st.button("‚¨ÜÔ∏è –í–≤–µ—Ä—Ö", key=f"{key}__up"):
            st.session_state[f"{key}__cwd"] = str(cwd.parent.resolve())
            cwd = Path(st.session_state[f"{key}__cwd"])
    with cols[1]:
        if st.button("–ü–µ—Ä–µ–π—Ç–∏", key=f"{key}__go"):
            p = Path(manual_path).expanduser()
            if p.exists() and p.is_dir():
                st.session_state[f"{key}__cwd"] = str(p.resolve())
                cwd = Path(st.session_state[f"{key}__cwd"])

    try:
        subdirs = sorted([p for p in cwd.iterdir() if p.is_dir()], key=lambda p: p.name.lower())
    except Exception:
        subdirs = []

    choice = st.sidebar.selectbox(
        "–ü–æ–¥–ø–∞–ø–∫–∏", options=["‚Äî –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–µ–∫—É—â—É—é ‚Äî"] + [d.name for d in subdirs], key=f"{key}__select"
    )
    if choice != "‚Äî –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–µ–∫—É—â—É—é ‚Äî":
        new_cwd = cwd / choice
        if new_cwd.exists():
            st.session_state[f"{key}__cwd"] = str(new_cwd.resolve())
            cwd = new_cwd

    st.sidebar.caption(f"–¢–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞: {cwd}")
    return str(cwd)


def quick_count_rows(path: str) -> int:
    """–ë—ã—Å—Ç—Ä—ã–π –ø–æ–¥—Å—á—ë—Ç —Å—Ç—Ä–æ–∫ (–º–∏–Ω—É—Å –∑–∞–≥–æ–ª–æ–≤–æ–∫). –î–µ–ª–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ –ø–æ —Ñ–∞–π–ª—É."""
    try:
        total = 0
        with open(path, "rb") as f:
            for _ in f:
                total += 1
        return max(0, total - 1)
    except Exception:
        return 0


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ UI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def page_header():
    st.title(APP_TITLE)
    st.caption("–í—ã–±–æ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ CSV ‚Üí –∫–æ–Ω—Ñ–∏–≥ –ø—Ä–∞–≤–∏–ª ‚Üí –∑–∞–ø—É—Å–∫ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ ‚Üí –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ –ª–æ–≥")


def sidebar_inputs():
    settings = load_settings()

    st.sidebar.header("–§–∞–π–ª—ã")
    mode = st.sidebar.radio("–ò—Å—Ç–æ—á–Ω–∏–∫ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞", ["–õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å", "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞"], index=0)

    input_path = None
    uploaded_tmp = None

    if mode == "–õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å":
        input_path = st.sidebar.text_input("–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É CSV", value="")
    else:
        up = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV", type=["csv"])
        if up is not None:
            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".csv")
            tmp.write(up.getbuffer())
            tmp.flush()
            tmp.close()
            uploaded_tmp = tmp.name
            input_path = uploaded_tmp

    st.sidebar.divider()
    st.sidebar.header("–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
    save_dir = folder_picker(
        "–í—ã–±–æ—Ä –ø–∞–ø–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è",
        start_path=Path(settings["save_dir"]),
        key="save_dir",
    )
    out_name = st.sidebar.text_input("–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ CSV", value=settings["out_name"])
    log_name = st.sidebar.text_input("–ò–º—è –ª–æ–≥–∞ (.txt)", value=settings["log_name"])
    output_path = str(Path(save_dir) / out_name) if out_name else ""
    log_path = str(Path(save_dir) / log_name) if log_name else ""

    st.sidebar.divider()
    st.sidebar.header("–ü—Ä–æ—Ñ–∏–ª—å –ø—Ä–∞–≤–∏–ª")
    profiles = [
        "configs/profiles/uni.yaml",
        "configs/profiles/minimal_email.yaml",
    ]
    prof_index = profiles.index(settings["profile"]) if settings["profile"] in profiles else 0
    profile = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ YAML-–ø—Ä–æ—Ñ–∏–ª—å", options=profiles, index=prof_index)

    st.sidebar.divider()
    delimiter = st.sidebar.text_input("–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å", value=settings["delimiter"])
    enc_options = ["auto", "utf-8", "cp1251", "latin1"]
    enc_index = enc_options.index(settings["encoding"]) if settings["encoding"] in enc_options else 0
    encoding = st.sidebar.selectbox("–ö–æ–¥–∏—Ä–æ–≤–∫–∞", options=enc_options, index=enc_index)
    chunksize = st.sidebar.number_input(
        "–†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞", min_value=10_000, max_value=2_000_000, step=50_000, value=int(settings["chunksize"])
    )

    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ–º
    st.sidebar.divider()
    st.sidebar.header("–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è")
    columns = read_columns_head(input_path, delimiter, encoding)
    dedup_enabled = st.sidebar.checkbox("–í–∫–ª—é—á–∏—Ç—å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é", value=bool(settings["dedup_enabled"]))
    # –≤—ã–±—Ä–∞—Ç—å –ø–æ–ª–µ –¥–ª—è –∫–ª—é—á–∞
    if columns:
        df_default_key = settings.get("dedup_field")
        key_idx = columns.index(df_default_key) if (df_default_key in columns) else 0
        dedup_field = st.sidebar.selectbox(
            "–ü–æ–ª–µ –¥–ª—è –¥–µ–¥—É–ø–∞ (–∫–ª—é—á)",
            options=columns,
            disabled=not (dedup_enabled and columns),
            index=key_idx,
        )
    else:
        dedup_field = ""
    dedup_subset = [dedup_field] if (dedup_enabled and columns and dedup_field) else []

    merge_candidates = [c for c in columns if c != dedup_field] if columns else []
    saved_merge = [c for c in settings.get("dedup_merge_columns", []) if c in merge_candidates]
    dedup_merge_columns = st.sidebar.multiselect(
        "–°—Ç–æ–ª–±—Ü—ã –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏–π —á–µ—Ä–µ–∑ ';'",
        options=merge_candidates,
        default=saved_merge,
        disabled=not (dedup_enabled and columns),
    )

    st.sidebar.divider()
    estimate_total_rows = st.sidebar.checkbox(
        "–û—Ü–µ–Ω–∏—Ç—å –æ–±—â–µ–µ —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–¥–æ–ø. –ø—Ä–æ—Ö–æ–¥ –ø–æ —Ñ–∞–π–ª—É)",
        value=bool(settings.get("estimate_total_rows", True)),
    )

    # –§–∏–ª—å—Ç—Ä —Å—Ç—Ä–æ–∫ ‚Äî —É–¥–∞–ª–∏—Ç—å, –µ—Å–ª–∏ —Ä–æ–≤–Ω–æ 1 –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–∞—è —Å—Ä–µ–¥–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö
    st.sidebar.divider()
    st.sidebar.header("–§–∏–ª—å—Ç—Ä —Å—Ç—Ä–æ–∫")
    rf_enabled = st.sidebar.checkbox(
        "–£–¥–∞–ª—è—Ç—å —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ —Å—Ä–µ–¥–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –∑–∞–ø–æ–ª–Ω–µ–Ω–∞ —Ä–æ–≤–Ω–æ 1 —è—á–µ–π–∫–∞",
        value=bool(settings.get("row_filter_one_filled_enabled", False)),
    )
    rf_subset_saved = [c for c in settings.get("row_filter_subset", []) if c in (columns or [])]
    rf_subset = st.sidebar.multiselect(
        "–°—Ç–æ–ª–±—Ü—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏",
        options=columns if columns else [],
        default=rf_subset_saved,
        disabled=not (rf_enabled and columns),
    )

    # –û—á–∏—Å—Ç–∫–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    st.sidebar.divider()
    st.sidebar.header("–û—á–∏—Å—Ç–∫–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
    ml_enabled = st.sidebar.checkbox(
        "–û—á–∏—â–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ—Ä–æ—á–µ N —Å–∏–º–≤–æ–ª–æ–≤",
        value=bool(settings.get("min_length_enabled", False))
    )
    ml_value = st.sidebar.number_input(
        "–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ (N)",
        min_value=1, max_value=100, step=1,
        value=int(settings.get("min_length_value", 3)),
        disabled=not ml_enabled
    )
    ml_cols_saved = [c for c in settings.get("min_length_columns", []) if c in (columns or [])]
    ml_columns = st.sidebar.multiselect(
        "–°—Ç–æ–ª–±—Ü—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª–∏–Ω—ã",
        options=columns if columns else [],
        default=ml_cols_saved,
        disabled=not (ml_enabled and columns),
    )

    # –¢–µ–ª–µ—Ñ–æ–Ω—ã ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ (E.164)
    st.sidebar.divider()
    st.sidebar.header("–¢–µ–ª–µ—Ñ–æ–Ω ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞")
    phone_prefix_strict_validate = st.sidebar.checkbox(
        "–ü—Ä–æ–≤–µ—Ä—è—Ç—å –∫–æ–¥—ã —Å—Ç—Ä–∞–Ω—ã (E.164) –∏ –æ—á–∏—â–∞—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ",
        value=bool(settings.get("phone_prefix_strict_validate", False)),
    )
    st.sidebar.caption("–ï—Å–ª–∏ –≤—ã–∫–ª—é—á–µ–Ω–æ ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ, —á—Ç–æ –¥–ª–∏–Ω–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ ‚â• 3 (–ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –≤–µ–¥—É—â–∏—Ö –Ω—É–ª–µ–π)")

    return (
        input_path,
        output_path,
        log_path,
        profile,
        delimiter,
        encoding,
        chunksize,
        uploaded_tmp,
        dedup_enabled,
        dedup_subset,
        dedup_merge_columns,
        save_dir,
        out_name,
        log_name,
        estimate_total_rows,
        dedup_field,  # —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –∏–º—è –∫–ª—é—á–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ (–∏–ª–∏ "")
        rf_enabled,
        rf_subset,
        ml_enabled,
        ml_value,
        ml_columns,
        phone_prefix_strict_validate,
    )


def show_preview(input_path: str, delimiter: str, encoding: str):
    st.subheader("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    if not input_path or not Path(input_path).exists():
        st.info("–£–∫–∞–∂–∏—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –≤—Ö–æ–¥–Ω–æ–π CSV, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä.")
        return

    try_order = [encoding] if encoding != "auto" else ["utf-8", "cp1251", "latin1"]
    df = None
    err = None
    for enc in try_order:
        try:
            df = pd.read_csv(
                input_path,
                sep=delimiter,
                nrows=200,
                dtype=str,
                keep_default_na=False,
                encoding=enc,
            )
            break
        except Exception as e:
            err = e
            continue

    if df is None:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV: {err}")
        return

    st.write(f"–°—Ç—Ä–æ–∫ –≤ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–µ: {len(df)}  ‚Ä¢  –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
    st.dataframe(df, use_container_width=True)


def run_button(
    input_path,
    output_path,
    log_path,
    profile,
    delimiter,
    encoding,
    chunksize,
    dedup_enabled,
    dedup_subset,
    dedup_merge_columns,
    save_dir,
    out_name,
    log_name,
    estimate_total_rows,
    dedup_field,
    rf_enabled,
    rf_subset,
    ml_enabled,
    ml_value,
    ml_columns,
    phone_prefix_strict_validate,
):
    st.subheader("–ó–∞–ø—É—Å–∫")
    can_run = all([input_path, output_path, log_path, profile])
    run = st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é", disabled=not can_run, type="primary")
    if not can_run:
        st.caption("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª, –ø–∞–ø–∫—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤, –∞ —Ç–∞–∫–∂–µ –ø—Ä–æ—Ñ–∏–ª—å –ø—Ä–∞–≤–∏–ª.")

    if run:
        # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞–ø–æ–∫
        try:
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            Path(log_path).parent.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–∞–ø–∫—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            return

        # —Å—á–∏—Ç–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        rows_est = None
        if estimate_total_rows and Path(input_path).exists():
            with st.spinner("–ü–æ–¥—Å—á—ë—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞‚Ä¶"):
                rows_est = quick_count_rows(input_path)

        # –ø—Ä–æ–≥—Ä–µ—Å—Å-UI
        prog = st.progress(0)
        status = st.empty()
        metrics_box = st.empty()

        def _progress_cb(info: dict):
            percent = info.get("percent")
            if percent is not None:
                prog.progress(int(percent))
            rows_done = info.get("rows_done", 0)
            rows_est_ = info.get("rows_est", None)
            elapsed = info.get("elapsed_sec", 0.0)
            rps = info.get("rps", 0.0)
            eta_txt = ""
            if rows_est_ and rows_est_ > 0 and rps and rps > 0:
                remain = max(0, rows_est_ - rows_done)
                eta = remain / rps
                eta_txt = f" ‚Ä¢ ETA ~ {int(eta)} —Å–µ–∫"
            status.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {rows_done}" + (f" / ~{rows_est_}" if rows_est_ else "") + eta_txt)
            metrics_box.markdown(f"**–°–∫–æ—Ä–æ—Å—Ç—å:** {rps:.2f} —Å—Ç—Ä–æ–∫/—Å–µ–∫ ‚Ä¢ **–ü—Ä–æ—à–ª–æ:** {elapsed:.1f} —Å–µ–∫")

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        save_settings({
            "save_dir": save_dir,
            "out_name": out_name,
            "log_name": log_name,
            "profile": profile,
            "delimiter": delimiter,
            "encoding": encoding,
            "chunksize": int(chunksize),

            "dedup_enabled": bool(dedup_enabled),
            "dedup_field": dedup_field,
            "dedup_merge_columns": list(dedup_merge_columns or []),

            "estimate_total_rows": bool(estimate_total_rows),

            "row_filter_one_filled_enabled": bool(rf_enabled),
            "row_filter_subset": list(rf_subset or []),

            "min_length_enabled": bool(ml_enabled),
            "min_length_value": int(ml_value),
            "min_length_columns": list(ml_columns or []),
            "phone_prefix_strict_validate": bool(phone_prefix_strict_validate),
        })

        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞‚Ä¶ —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è –Ω–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–∞—Ö"):
            run_pipeline(
                input_csv=input_path,
                output_csv=output_path,
                config_yaml=profile,
                log_txt=log_path,
                chunksize=int(chunksize),
                delimiter_override=delimiter,
                encoding_override=encoding,

                dedup_enabled=dedup_enabled,
                dedup_subset=dedup_subset,
                dedup_merge_columns=dedup_merge_columns,

                progress_cb=_progress_cb,
                rows_total_estimate=rows_est,

                row_filter_one_filled_enabled=rf_enabled,
                row_filter_subset=rf_subset,

                min_length_enabled=ml_enabled,
                min_length_value=int(ml_value),
                min_length_columns=ml_columns,
                phone_prefix_strict_validate=bool(phone_prefix_strict_validate),
            )

        prog.progress(100)
        st.success("–ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç –∏ –ª–æ–≥ –∑–∞–ø–∏—Å–∞–Ω—ã.")

        # –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª—ã
        st.subheader("–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        try:
            if Path(output_path).exists():
                with open(output_path, "rb") as fh:
                    st.download_button(
                        "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å CSV", data=fh.read(), file_name=Path(output_path).name, mime="text/csv"
                    )
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å CSV –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")

        try:
            if Path(log_path).exists():
                with open(log_path, "rb") as fh:
                    st.download_button(
                        "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –ª–æ–≥ (.txt)", data=fh.read(), file_name=Path(log_path).name, mime="text/plain"
                    )
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ª–æ–≥ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")

        # –ü–æ–∫–∞–∑–∞—Ç—å —Ö–≤–æ—Å—Ç –ª–æ–≥–∞
        try:
            with open(log_path, "r", encoding="utf-8") as fh:
                text = fh.read()
            st.subheader("–õ–æ–≥ (—Ñ—Ä–∞–≥–º–µ–Ω—Ç)")
            st.text(text[-8000:])
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ª–æ–≥: {e}")


def main():
    page_header()
    (
        input_path,
        output_path,
        log_path,
        profile,
        delimiter,
        encoding,
        chunksize,
        uploaded_tmp,
        dedup_enabled,
        dedup_subset,
        dedup_merge_columns,
        save_dir,
        out_name,
        log_name,
        estimate_total_rows,
        dedup_field,
        rf_enabled,
        rf_subset,
        ml_enabled,
        ml_value,
        ml_columns,
        phone_prefix_strict_validate,
    ) = sidebar_inputs()
    show_preview(input_path, delimiter, encoding)
    run_button(
        input_path,
        output_path,
        log_path,
        profile,
        delimiter,
        encoding,
        chunksize,
        dedup_enabled,
        dedup_subset,
        dedup_merge_columns,
        save_dir,
        out_name,
        log_name,
        estimate_total_rows,
        dedup_field,
        rf_enabled,
        rf_subset,
        ml_enabled,
        ml_value,
        ml_columns,
        phone_prefix_strict_validate,
    )

    # –æ—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if uploaded_tmp and Path(uploaded_tmp).exists():
        try:
            os.remove(uploaded_tmp)
        except Exception:
            pass


if __name__ == "__main__":
    main()
